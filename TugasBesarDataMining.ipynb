{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8b6c3950-a274-4b3f-af01-2dc9bd8f1a3b",
   "metadata": {},
   "source": [
    "Tugas Besar Teknik Penambangan Data - Jakarta Air Quality Index Classification\n",
    "\n",
    "Kevin Philips Tanamas - 220711789\n",
    "Richard Angelico - 220711747\n",
    "Dhiaz Juan - 220711695\n",
    "Nathanael Esmond - "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f3c0800f-2cf4-46a4-b71d-231f36abadcb",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'imblearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 41\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mneural_network\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MLPClassifier\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msvm\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SVC\n\u001b[0;32m---> 41\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mimblearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mover_sampling\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SMOTE\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'imblearn'"
     ]
    }
   ],
   "source": [
    "# Import semua library\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "import tensorflow as tf\n",
    "import altair as alt\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "import missingno as msno\n",
    "\n",
    "from datetime import datetime\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from pandas.api.types import is_numeric_dtype\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c34d0646-2b1d-4660-a52c-b3f150287038",
   "metadata": {},
   "source": [
    "DATA LOADING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a6c4e9f-1408-42bc-92a8-d4273842c84e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Loading\n",
    "all_data = pd.read_csv(r\"ispu_dki_all.csv\")\n",
    "all_data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "279f0dcf-e9c5-4a04-8202-e6c46ea3283d",
   "metadata": {},
   "source": [
    "DATA CLEANSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22dedb3b-5087-4752-ad4d-501807f6fe84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing Data - Missing Value (sebelum imputasi)\n",
    "datasets = {\n",
    "    \"Jakarta Highest AQI Data\": all_data\n",
    "}\n",
    "\n",
    "for name, data in datasets.items():\n",
    "    print(f\"\\n{name} Dataset:\")\n",
    "    print(data.info())\n",
    "    print(\"\\nMissing Value Report:\")\n",
    "    print(data.isnull().sum())\n",
    "\n",
    "    msno.matrix(data, figsize=(10, 5), fontsize=12)\n",
    "    plt.title(f\"Before Imputation Missing Value Matrix: {name}\", fontsize=14)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "327f2a6d-422a-44d4-97f9-3266b7ba6a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing Data - Data Cleansing pada dataframe all_data\n",
    "all_data.drop(columns=['pm25'], inplace=True)\n",
    "\n",
    "numerical_columns = all_data.select_dtypes(include=['float64', 'int64']).columns\n",
    "for col in numerical_columns:\n",
    "    all_data[col] = all_data[col].fillna(all_data[col].mean())\n",
    "\n",
    "categorical_columns = all_data.select_dtypes(include=['object']).columns\n",
    "for col in categorical_columns:\n",
    "    all_data[col] = all_data[col].fillna(all_data[col].mode()[0])\n",
    "\n",
    "print(all_data.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c321303-0a44-4303-be64-000525793030",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing Data - Missing Value (sesudah imputasi dan dropping)\n",
    "datasets = {\n",
    "    \"Jakarta Highest AQI Data\": all_data\n",
    "}\n",
    "\n",
    "for name, data in datasets.items():\n",
    "    print(f\"\\n{name} Dataset:\")\n",
    "    print(data.info())\n",
    "    print(\"\\nMissing Value Report:\")\n",
    "    print(data.isnull().sum())\n",
    "\n",
    "    msno.matrix(data, figsize=(10, 5), fontsize=12)\n",
    "    plt.title(f\"After Imputation Missing Value Matrix: {name}\", fontsize=14)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1df01f4a-b29b-4e63-b87a-8d898505c79c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Menambahkan atribut rata-rata polutan per hari dan indikator weekend/weekday\n",
    "\n",
    "all_data['rata_rata_polutan'] = all_data[['pm10', 'so2', 'co', 'o3', 'no2']].mean(axis=1)\n",
    "all_data['tanggal'] = pd.to_datetime(all_data['tanggal'])\n",
    "all_data['weekday_weekend'] = all_data['tanggal'].dt.dayofweek.apply(lambda x: 'Weekend' if x >= 5 else 'Weekday')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd650d27-1016-48bf-a63d-48a6bf008b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Konversi datetime dan hapus kolom 'tanggal'\n",
    "\n",
    "all_data['year'] = pd.to_datetime(all_data['tanggal']).dt.year\n",
    "all_data['month'] = pd.to_datetime(all_data['tanggal']).dt.month\n",
    "all_data['day'] = pd.to_datetime(all_data['tanggal']).dt.day\n",
    "all_data.drop(columns=['tanggal'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce287db5-7998-4304-9095-56fe66467364",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe08003b-2b8e-4684-9772-72af1d68b08e",
   "metadata": {},
   "source": [
    "Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95159122-fd93-4f61-82ad-3c734ca57755",
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_cols = ['pm10', 'so2', 'co', 'o3', 'no2', 'rata_rata_polutan']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c941b1e9-9633-4dcd-962c-1a5518ded321",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisasi Distribusi Kolom Numerik\n",
    "alt.Chart(all_data).transform_fold(\n",
    "    numerical_cols,\n",
    "    as_=['Variable', 'Value']\n",
    ").mark_area(\n",
    "    opacity=0.5\n",
    ").encode(\n",
    "    alt.X('Value:Q', bin=alt.Bin(maxbins=30)),\n",
    "    alt.Y('count()'),\n",
    "    alt.Color('Variable:N')\n",
    ").properties(\n",
    "    title='Distribution of Numerical Columns',\n",
    "    width=600,\n",
    "    height=400\n",
    ").interactive()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f64fbe8-9a2e-4bff-9c5b-4e2b2ad7458c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisasi Outlier\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.boxplot(data=all_data[numerical_cols], palette='Set3')\n",
    "plt.title('Boxplot untuk Deteksi Outlier', fontsize=14)\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74e41c18-7d37-45c1-abf5-8f0deb66603c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisasi Heatmap Korelasi Antar Variabel\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "corr_matrix = all_data[numerical_cols].corr()\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt='.2f', square=True)\n",
    "plt.title('Correlation Matrix Antar Variabel', fontsize=14)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da628489-57b0-4a08-8c90-b6c285adb4e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisasi Rata-rata polutan dari waktu ke waktu\n",
    "temp_df = all_data\n",
    "temp_df['datetime'] = pd.to_datetime(all_data[['year', 'month', 'day']])\n",
    "\n",
    "alt.Chart(temp_df).mark_line().encode(\n",
    "    x=alt.X('datetime:T', title='Waktu'),\n",
    "    y=alt.Y('rata_rata_polutan:Q', title='Rata-rata Polutan'),\n",
    "    tooltip=['datetime:T', 'average_pollutant:Q']\n",
    ").properties(\n",
    "    title='Rata-rata Polutan dari Waktu ke Waktu',\n",
    "    width=800,\n",
    "    height=400\n",
    ").interactive()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b119f299-b840-44bf-b7d5-a5c2b90ae172",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisasi Categori dari Waktu ke Waktu\n",
    "\n",
    "data_categori = all_data.groupby(['year', 'month', 'categori']).size().reset_index(name='count')\n",
    "\n",
    "chart = alt.Chart(data_categori).mark_bar().encode(\n",
    "    x=alt.X('month:O', title='Month'), \n",
    "    y=alt.Y('count:Q', title='Count'),\n",
    "    color='categori:N',  \n",
    "    column='year:O',  \n",
    ").properties(\n",
    "    title='Distribusi Kategori Kualitas Udara Jakarta dari Waktu ke Waktu'\n",
    ")\n",
    "\n",
    "chart.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab772edf-5eac-46ff-a24f-507997b793b9",
   "metadata": {},
   "source": [
    "PENGECEKAN DATA DUPLIKAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2434ea29-0864-4fb0-9702-082a215bfd08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pengecekan data duplikat\n",
    "print(\"Before checking for duplicates: \", all_data.shape)\n",
    "all_data = all_data[~all_data.duplicated(keep='last')]\n",
    "print(\"After checking for duplicates: \", all_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2474ec13-2034-407d-beb2-00e7c8a0c8d8",
   "metadata": {},
   "source": [
    "PEMBERSIHAN OUTLIER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "564c76b6-f5cb-4382-b3f2-ce11192e3991",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pembersihan Data Outlier memakai IQR\n",
    "\n",
    "cols = ['pm10', 'so2', 'co', 'o3', 'no2', 'rata_rata_polutan']\n",
    "\n",
    "def remove_outlier(df_in, cols):\n",
    "    df_out = df_in.copy()\n",
    "    for col_name in cols:\n",
    "        if is_numeric_dtype(df_out[col_name]):  # Cek apakah kolom numerik\n",
    "            q1 = df_out[col_name].quantile(0.25)\n",
    "            q3 = df_out[col_name].quantile(0.75)\n",
    "            iqr = q3 - q1\n",
    "            upper_bound = q3 + (iqr * 1.5)\n",
    "            lower_bound = q1 - (iqr * 1.5)\n",
    "\n",
    "            # Hapus baris yang berada di luar batas IQR untuk kolom tersebut\n",
    "            df_out = df_out[(df_out[col_name] >= lower_bound) & (df_out[col_name] <= upper_bound)]\n",
    "    return df_out\n",
    "\n",
    "# Panggil fungsi untuk membersihkan data\n",
    "all_data_cleaned = remove_outlier(all_data, cols)\n",
    "\n",
    "# Cek hasil pembersihan\n",
    "print(\"Number of rows before removing outliers: \", all_data.shape[0])\n",
    "print(\"Number of rows after removing outliers: \", all_data_cleaned.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "916a37b6-f0c9-47c9-86ee-f6862d76a29e",
   "metadata": {},
   "source": [
    "DATA ENCODING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b83cb58-92c5-40f5-9c6d-8cc975cc145c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label Encoding untuk Data Non-Numerik\n",
    "label_encoder = LabelEncoder()\n",
    "all_data_cleaned['stasiun'] = label_encoder.fit_transform(all_data_cleaned['stasiun'])\n",
    "all_data_cleaned['critical'] = label_encoder.fit_transform(all_data_cleaned['critical'])\n",
    "all_data_cleaned['weekday_weekend'] = label_encoder.fit_transform(all_data_cleaned['weekday_weekend'])\n",
    "all_data_cleaned['categori'] = label_encoder.fit_transform(all_data_cleaned['categori'])\n",
    "all_data_cleaned.drop(columns=['datetime'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cec6d07-f88d-476f-9efe-1eae02aa1580",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Scaling & Train-test split\n",
    "\n",
    "x = all_data_cleaned.drop(['categori', 'stasiun'], axis = 1).values\n",
    "y = all_data_cleaned.categori.values\n",
    "\n",
    "# Normalisasi Data\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(x)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X_scaled,y,test_size=0.25, random_state=15)\n",
    "\n",
    "smote = SMOTE(random_state=42)\n",
    "x_train, y_train = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7f04b65-e53c-4c00-813c-9b30cceaf898",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest Modeling\n",
    "rf_model = RandomForestClassifier(n_estimators=200, random_state=42)\n",
    "rf_model.fit(x_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred_rf = rf_model.predict(x_test)\n",
    "\n",
    "print(\"Building Model Random Forest...\")\n",
    "print(classification_report(y_test, y_pred_rf))\n",
    "print(\"Feature Importances:\", rf_model.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d420f1e-7906-494c-9528-8eafa78cb9d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suport Vector Machine Model\n",
    "\n",
    "svm_model = SVC(kernel='rbf', probability=True, random_state=42)\n",
    "\n",
    "# Model Training\n",
    "svm_model.fit(x_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred_svm = svm_model.predict(x_test)\n",
    "y_pred_svm_proba = svm_model.predict_proba(x_test)\n",
    "\n",
    "print(\"Building Model SVM...\")\n",
    "print(classification_report(y_test, y_pred_rf))\n",
    "print(\"Feature Importances:\", svm_model.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2395c07c-025a-4f73-8b85-5aded8595912",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multi-layer Perceptron Classifier Model\n",
    "\n",
    "mlp_model = MLPClassifier(hidden_layer_sizes=(64, 32), activation='relu', solver='adam', max_iter=300, random_state=42)\n",
    "mlp_model.fit(x_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred_mlp = mlp_model.predict(x_test)\n",
    "\n",
    "print(\"Building Model MLP...\")\n",
    "print(classification_report(y_test, y_pred_rf))\n",
    "print(\"Feature Importances:\", mlp_model.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c566273a-9ce0-48c5-976e-df01c4d3fa31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluasi 3 Model Klasifikasi - Confusion Matrix\n",
    "\n",
    "model_names = ['Random Forest', 'MLP', 'SVM']\n",
    "conf_matrices = [\n",
    "    confusion_matrix(y_test, y_pred_rf),\n",
    "    confusion_matrix(y_test, y_pred_mlp),\n",
    "    confusion_matrix(y_test, y_pred_svm)\n",
    "]\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(30, 8))\n",
    "for i, (model_name, conf_matrix) in enumerate(zip(model_names, conf_matrices)):\n",
    "    sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"YlGnBu\", ax=axes[i])\n",
    "    axes[i].set_title(f'{model_name} Confusion Matrix')\n",
    "    axes[i].set_xlabel(\"Predicted\")\n",
    "    axes[i].set_ylabel(\"Actual\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b35c2ea-30b8-4e89-9aa2-23a761b00c36",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Kernel untuk Data Mining",
   "language": "python",
   "name": "data_mining"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
